<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Stuff I worked on</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-06-14T14:03:00-04:00</updated><entry><title>Adding Custom Builtin Functions to the Python Interpreter</title><link href="/adding-custom-builtin-functions-to-the-python-interpreter.html" rel="alternate"></link><published>2016-06-14T14:03:00-04:00</published><author><name>Lenard Chan</name></author><id>tag:,2016-06-14:adding-custom-builtin-functions-to-the-python-interpreter.html</id><summary type="html">&lt;p&gt;When I have a few minutes of spare time, like if I’m on the bus heading to work or waiting for class to start, one of the things I like to do is explore the cpython source code. I want to learn how the Python interpreter works as a way to become a better Python programmer (or just a better programmer in general), and perhaps someday contribute to the development of Python in later releases.&lt;/p&gt;
&lt;h1&gt;Objective&lt;/h1&gt;
&lt;p&gt;One of the first things I did to get more familiar with the source is add my own custom builtin functions to the interpreter. I’m not talking about making a new function in python like &lt;code&gt;def func(args)&lt;/code&gt;. I’m also not talking about making an extension module in C that can be imported in python like &lt;code&gt;from my_c_module import my_c_func&lt;/code&gt;. I’m talking about adding a new one of &lt;a href="https://docs.python.org/3/library/functions.html"&gt;these functions&lt;/a&gt;: functions like &lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;abs()&lt;/code&gt;, and &lt;code&gt;range()&lt;/code&gt; that are automatically built into the langauge and do not require manually importing anything to use. I figured this would be a good way to learn more about the source since I’d be learning how the core functions, which are part of the source, are implemented and used.&lt;/p&gt;
&lt;p&gt;The function I will be adding for this example is a simple product function which will take the product of a list of numbers, similar to sum, but with multiplying instead of adding and a starting value of 1. Now, I know the idea of a product function has been &lt;a href="http://bugs.python.org/issue1093"&gt;proposed before and rejected due to low demand for the function&lt;/a&gt;, and there are &lt;a href="http://stackoverflow.com/questions/595374/whats-the-python-function-like-sum-but-for-multiplication-prod"&gt;many existing ways to impliment this function in python&lt;/a&gt;, but this is just for learning purposes.&lt;/p&gt;
&lt;h2&gt;Python Version&lt;/h2&gt;
&lt;p&gt;The version of python I am also working with is the first alpha version of Python 3.6.0 (more specifically, &lt;a href="https://docs.python.org/dev/"&gt;3.6.0a1&lt;/a&gt;). The reason I am working with python 2 instead of 3 is because nearly all active development is in python 3, and the latest version of python 2 at the time (2.7.11) is only receiving bug fixes and backporting from python 3. &lt;a href="https://www.python.org/dev/peps/pep-0404/"&gt;There is a whole PEP dedicated to why Python 2.8 will never be a thing&lt;/a&gt;. You know it’s serious because the PEP number is 404. The reason I am also working with an alpha version of python 3 instead of the latest release at the time (3.5.1) is because I accidentally cloned the cpython repo from github without asserting first that the master branch contained the latest release version instead of development version.&lt;br /&gt;
¯\_(ツ)_/¯&lt;/p&gt;
&lt;h1&gt;How it works&lt;/h1&gt;
&lt;p&gt;Now, I kind of lied when I mentioned not making a C extension. It turns out that adding a builtin function is a lot like making a C extension for python. There are already lots of articles and documentation on the internet about making C extensions, especially &lt;a href="http://dan.iel.fm/posts/python-c-extensions/"&gt;this one&lt;/a&gt;, so I will not go into great detail about making one from scratch, just how it gets added and what changes I made to the source.&lt;/p&gt;
&lt;p&gt;When you normally make a C extension, you add a &lt;code&gt;PyMethodDef&lt;/code&gt; struct to an array of PyMethodDef structs which represent the functions you would like to expose in python space. These PyMethodDef structs is given as:&lt;/p&gt;
&lt;pre&gt;&lt;code class="C"&gt;struct PyMethodDef {
    const char *ml_name; /* The name of the built-in function/method */
    PyCFunction ml_meth; /* The C function that implements it */
    int ml_flags; /* Combination of METH_xxx flags, which mostly describe the args expected by the C func */
    const char *ml_doc; /* The __doc__ attribute, or NULL */
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hopefully the comments in this code, taken straight from the source, are enough to explain the individual members of the struct.&lt;/p&gt;
&lt;p&gt;Inside &lt;code&gt;Python/bltinmodule.c&lt;/code&gt;, the array of PyMethodDef structs this gets added to is:&lt;/p&gt;
&lt;pre&gt;&lt;code class="C"&gt;static PyMethodDef builtin_methods[] = {
    {&amp;quot;__build_class__&amp;quot;, (PyCFunction)builtin___build_class__, METH_VARARGS | METH_KEYWORDS, build_class_doc},
    {&amp;quot;__import__&amp;quot;, (PyCFunction)builtin___import__, METH_VARARGS | METH_KEYWORDS, import_doc},
    BUILTIN_ABS_METHODDEF
    BUILTIN_ALL_METHODDEF
    …
    {&amp;quot;vars&amp;quot;,            builtin_vars,       METH_VARARGS, vars_doc},
    {NULL, NULL},
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the source, some of the array elements are given as literal structs while others like &lt;code&gt;BUILTIN_ABS_METHODDEF&lt;/code&gt; are implemented as macros. You may notice that this array does not contain all builtin functions. The remaining functions like &lt;code&gt;bytearray()&lt;/code&gt;, &lt;code&gt;int()&lt;/code&gt;, or &lt;code&gt;str()&lt;/code&gt; are actually constructors located in the &lt;code&gt;_PyBuiltin_Init&lt;/code&gt;method also in &lt;code&gt;Python/bltinmodule.c&lt;/code&gt;. (I don’t like using the word constructor when referencing these in python, but that’s another story.)&lt;/p&gt;
&lt;p&gt;So, in order to add my custom builtin method, I just need to add a PyMethodDef to this array containing my function name, implementation, argument flags, and docstring.&lt;/p&gt;
&lt;h1&gt;Implementation&lt;/h1&gt;
&lt;p&gt;All changes implemented are in my copy of the source on &lt;a href="https://github.com/PiJoules/cpython-modified"&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I decided to try and isolate my additions as much as possible from the existing source so that it would be easier to reference later by making my changes stand out. The actual implementation of my builtin product function is pretty much an exact copy of the builtin sum function with a few minor changes.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://github.com/PiJoules/cpython-modified/blob/master/Custom/custom.c"&gt;Custom/custom.c&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This file contains the implementation of my product function and the wrapper for it.&lt;/p&gt;
&lt;p&gt;The implementation (builtin_prod_impl) does the exact same stuff as builtin_sum_impl, but with the default value changed from 0 to 1, the actual addition done by PyNumber_Add changed to PyNumber_Multiply for multiplication, and Fast Addition was removed. This Fast Addition was a way to speed up addition by storing the temporary sum in C space instead of Python space. The downside of this is that you always need to check for overflow since you’re working with data types that have a limited range of values. Now this can easily, and quickly, be done by comparing the sign bit of your result against the sign bit of your two numbers that you’re adding (which the interpreter does in this fast addition). However, for multiplication, I cannot find a quick way for checking if overflow occurred that does not involve dividing the product by one of the two numbers to get the other. Regardless, I ended up just using python’s builtin objects for multiplication since they handle overflow and large numbers already.&lt;/p&gt;
&lt;p&gt;I have not profiled this, but I am curious to see if multiplying in C and dividing to check for overflow will still outperform PyNumber_Multiply.&lt;/p&gt;
&lt;p&gt;The wrapper (builtin_prod) essentially unpacks the arguments into the iterable and starting value for the implementation.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://github.com/PiJoules/cpython-modified/blob/master/Custom/custom.h"&gt;Custom/custom.h&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This file just contains the declarations for builtin_prod_impl and builtin_prod, the docstring, and the final macro to be included in the original &lt;code&gt;builtin_methods&lt;/code&gt; array.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://github.com/PiJoules/cpython-modified/blob/master/Python/bltinmodule.c"&gt;Python/bltinmodule.c&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To actually my &lt;code&gt;prod()&lt;/code&gt; function to the builtin functions, I just needed to add my macro to the array of builtin functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class="C"&gt;static PyMethodDef builtin_methods[] = {
    {&amp;quot;__build_class__&amp;quot;, (PyCFunction)builtin___build_class__, METH_VARARGS | METH_KEYWORDS, build_class_doc},
    {&amp;quot;__import__&amp;quot;, (PyCFunction)builtin___import__, METH_VARARGS | METH_KEYWORDS, import_doc},
    BUILTIN_ABS_METHODDEF
    BUILTIN_ALL_METHODDEF
    …
    {&amp;quot;vars&amp;quot;,            builtin_vars,       METH_VARARGS, vars_doc},
#ifdef USE_CUSTOM_BUILTINS
    BUILTIN_PROD_METHODDEF
#endif
    {NULL, NULL},
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;USE_CUSTOM_BUILTINS&lt;/code&gt; is just a flag I can pass to the compiler that says whether or not I want to include whatever custom builtin functions I had.&lt;/p&gt;
&lt;h2&gt;Makefile&lt;/h2&gt;
&lt;p&gt;The last thing to do was just adjust the Makefile such that it accepted this flag, and compiled the product function. Nothing big.&lt;/p&gt;
&lt;h1&gt;Usage&lt;/h1&gt;
&lt;p&gt;After re-building python from source, I am able to use &lt;code&gt;prod()&lt;/code&gt; in both the shell and from a python script.&lt;/p&gt;
&lt;pre&gt;&lt;code class="python"&gt;&amp;gt;&amp;gt;&amp;gt; prod(range(1, 6))
120
&amp;gt;&amp;gt;&amp;gt; prod([])  # Empty iterable, default starting value of 1
1
&amp;gt;&amp;gt;&amp;gt; prod(range(5))  # Zero included
0
&amp;gt;&amp;gt;&amp;gt; prod(range(-3, 4, 2))  # Negative numbers, positive result
9
&amp;gt;&amp;gt;&amp;gt; prod(range(-5, 4, 2))  # Negative numbers, negative result
-45
&amp;gt;&amp;gt;&amp;gt; prod((1, 2), 10)  # New starting value
20
&amp;gt;&amp;gt;&amp;gt; prod([2, 2**64]) == 2**65
True
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;Hopefully, this serves as a nice introduction into how new builtin functions are added. Feel free to send me an email if there’s anything blatantly wrong in this article.&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/PiJoules/cpython-modified"&gt;Source&lt;/a&gt;&lt;/p&gt;</summary><category term="Python"></category><category term="Builtin Functions"></category><category term="C"></category><category term="Extension"></category></entry><entry><title>Fourier Transform Notes</title><link href="/fourier-transform-notes.html" rel="alternate"></link><published>2016-06-13T16:13:00-04:00</published><author><name>Leonard Chan</name></author><id>tag:,2016-06-13:fourier-transform-notes.html</id><summary type="html">&lt;p&gt;These are just notes I put on this website so that I will be able to remeber the content and be able to review it easly for later exams. This is not meant to go into full detail about the Fourier Transform, so stuff like derivations and proofs will not be included b/c deriving this stuff requires a lot more research than I'd like to do.&lt;/p&gt;
&lt;h1&gt;Fourier Transform&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Fourier Transform&lt;/strong&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$ F\{x(t)\} = X(\omega) = \int_{-\infty}^{\infty} x(t)e^{-j \omega t}dt $$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Inverse Fourier Transform&lt;/strong&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$ F^{-1}\{X(\omega)\} = x(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty} X(\omega)e^{j \omega t}d\omega $$&lt;/div&gt;
&lt;p&gt;One of the main purposes of the Fourier Transform is to point out the dominant frequencies of a waveform. This can easily be seen with the FT of a regular sine or cosine wave.&lt;/p&gt;
&lt;p&gt;&lt;img alt="FT and IFT of cosine wave" src="/images/fourier/cosine.png" /&gt;&lt;/p&gt;
&lt;p&gt;The FT of a cosine wave is the dirac delta functions at &lt;span class="math"&gt;\(+ω_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(-ω_0\)&lt;/span&gt;. This makes sense since the only frequency in a regular cosine wave is &lt;span class="math"&gt;\(ω_0\)&lt;/span&gt;. The reason for the peak at &lt;span class="math"&gt;\(-ω_0\)&lt;/span&gt; is because &lt;strong&gt;the FT of real waves are always symmetrical across the initial phase shift&lt;/strong&gt;. In this case, φ = 0, so the FT of &lt;span class="math"&gt;\(cos(2πt)\)&lt;/span&gt; will be symmetrical across the y-axis.&lt;/p&gt;
&lt;p&gt;For the example above, the FT is not an exact dirac function since I am only integrating over a finite set of data rather than an infinite set from t = -∞ to +∞. If I had more data points, the peaks would stand out more. Similarly, the reconstruction of x(t) from X(ω) is not exactly the same as the original x(t) because of the finite amount of data points I am integrating over in the frequency domain. &lt;strong&gt;For the continuous FT, the FT converts continuous data in the time domain to continous data in the frequency domain.&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;Discrete Time Fourier Transform&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Discrete Time Fourier Transform of x[n]&lt;/strong&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$ X_{s}(\Omega) = \sum_{n=-\infty}^{\infty} x[n]e^{-j \Omega n} $$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Inverse Fourier Transform of X(ω)&lt;/strong&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$ x[n] = \frac{1}{2\pi} \int_{2\pi} X_s(\Omega) e^{j \Omega n} d\Omega $$&lt;/div&gt;
&lt;p&gt;In the real world though, data is not necessarily continuous. In the example used to generate x(t), I just found x(t) at very small increments of t to replicate continuous data. Really, I just took discrete values of x(t) sampled every Ts seconds. The DTFT allows us to essentially take the Fourier Transform of discrete/sampled data, though the spectrum is different in the frequency domain than the continuous FT.&lt;/p&gt;
&lt;p&gt;&lt;img alt="continuous and discrete cosine wave" src="/images/fourier/cosinediscrete.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="FT and DTFT of cosine wave" src="/images/fourier/cosinedtft.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Comparison between reconstructed discrete cosine wave and original" src="/images/fourier/cosinedtftreconstruct.png" /&gt;&lt;/p&gt;
&lt;p&gt;In the example above, I take the FT of a continuous cosine wave and the DTFT of the cosine wave sampled every Ts seconds. In this case, Ts = 0.05 s and my sampling frequency (fs) = 20 Hz. The FT of x(t) returns X(ω), which should be two dirac delta functions at positive and negative &lt;span class="math"&gt;\(ω_0\)&lt;/span&gt;. The DTFT of x[n], however, returns Xs(Ω). This spectrum is different from that of the FT in that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;The DTFT is in terms of Ω while the FT is in terms of ω, where &lt;span class="math"&gt;\(X_s(Ω)\)&lt;/span&gt; = &lt;span class="math"&gt;\(X_s(ωTs)\)&lt;/span&gt;.&lt;/strong&gt; (A similar example of this notation is how x[n] = x(nTs).) Though both have the same units (rad/s), the scale of the DTFT is smaller than that of the FT by a factor of the sampling frequency (fs = 1/Ts).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The DTFT repeats every 2π.&lt;/strong&gt; This is because the DTFT is the sum of various FTs at frequencies that are 2π apart from each other.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The DTFT transforms discrete data from the time domain to continuous data in the frequency domain&lt;/strong&gt; while the FT transforms continuous data in the time domain to continuous data in the frequency domain.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Like the IFT, the original discrete signal can also be reconstructed from its DTFT. Theoretically, the continuous signal could be constructed from the discrete signal, though this would require an infinitely large sampling frequency to replicate an infinitesimally small dt.&lt;/p&gt;
&lt;h1&gt;Resources&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.mechmat.ethz.ch/Lectures/tables.pdf"&gt;Fourier Transforms Table&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Source Code&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Matlab&lt;ul&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/PiJoules/cae4321693638e082495"&gt;Cosine Fourier Transform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/PiJoules/e553751fdfad0338865a"&gt;Cosine Discrete Time Fourier Transform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' }, Macros: {} }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="Fourier Transform"></category><category term="Notes"></category></entry><entry><title>Test Github Post</title><link href="/test-github-post.html" rel="alternate"></link><published>2016-06-12T15:37:00-04:00</published><author><name>Leonard Chan</name></author><id>tag:,2016-06-12:test-github-post.html</id><summary type="html">&lt;p&gt;This is a placeholder for Github Projects category.&lt;/p&gt;</summary></entry></feed>